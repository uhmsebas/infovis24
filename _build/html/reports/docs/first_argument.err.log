Traceback (most recent call last):
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/sebastiaan/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import pandas as pd
import geopandas as gpd
import plotly.graph_objects as go

# Load the CSV file
data = pd.read_csv('Normalized_Dataset_EDU.csv')

# Convert the 'GDP' and 'Life expectancy' columns to numeric
data['Value'] = pd.to_numeric(data['Value'], errors='coerce')
data['Life expectancy'] = pd.to_numeric(data['Life expectancy'], errors='coerce')

# Load the dataset with country borders
border = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
border = border[border['name'] != 'Antarctica']

# Merge the non-spatial data with the spatial GeoDataFrame based on the country name
merged_data = border.merge(data, left_on='name', right_on='Country')

# Ensure the GeoDataFrame has a CRS set
if merged_data.crs is None:
    merged_data = merged_data.set_crs('EPSG:4326')  # Assuming WGS84

# Add the 'Bi_Class' column to your data for bivariate choropleth
merged_data['Bi_Class'] = pd.qcut(merged_data['Value'], 3, labels=['low', 'medium', 'high']).astype(str) + \
                          pd.qcut(merged_data['Life expectancy'], 3, labels=['_low', '_medium', '_high']).astype(str)

# Define custom colors for each category with ordered keys
ordered_categories = ['low_low', 'low_medium', 'low_high',
                      'medium_low', 'medium_medium', 'medium_high',
                      'high_low', 'high_medium', 'high_high']
category_colors = {
    'low_low': '#ffffe5',  # low GDP, low life expectancy
    'low_medium': '#f7fcb9',  # low GDP, medium life expectancy
    'low_high': '#d9f0a3',  # low GDP, high life expectancy
    'medium_low': '#addd8e',  # medium GDP, low life expectancy
    'medium_medium': '#78c679',  # medium GDP, medium life expectancy
    'medium_high': '#41ab5d',  # medium GDP, high life expectancy
    'high_low': '#238443',  # high GDP, low life expectancy
    'high_medium': '#006837',  # high GDP, medium life expectancy
    'high_high': '#004529'  # high GDP, high life expectancy
}
merged_data['color'] = merged_data['Bi_Class'].map(category_colors)

# Prepare the data for Plotly
merged_data['iso_a3'] = merged_data['iso_a3'].apply(lambda x: x if x != -99 else None)

# Create the Plotly figure
fig = go.Figure()

# Add choropleth traces in the order of the categories
for category in ordered_categories:
    subset = merged_data[merged_data['Bi_Class'] == category]
    fig.add_trace(go.Choropleth(
        locations=subset['iso_a3'],
        z=subset['Value'],  # Here, use GDP for the color intensity
        text=subset.apply(lambda row: f"{row['name']}<br>Bi-Class: {row['Bi_Class']}<br>GDP: {row['Value']}<br>Life Expectancy: {row['Life expectancy']}", axis=1),
        hoverinfo='text',
        geo='geo',
        colorscale=[[0, category_colors[category]], [1, category_colors[category]]],
        showscale=False,
        name=category.replace('_low', '_Low Education & L.E').replace('_medium', '_Medium Education & L.E').replace('_high', '_High Education & L.E').replace('low', 'Low Education').replace('medium', 'Medium Education').replace('high', 'High Education')  # Update the category name
    ))

# Add custom legend using scattergeo
for category in ordered_categories:
    fig.add_trace(go.Scattergeo(
        locationmode='ISO-3',
        locations=[None],  # No actual points, just for the legend
        marker=dict(
            size=10,
            color=category_colors[category],
        ),
        showlegend=True,
        name=category.replace('_low', '_Low L.E').replace('_medium', '_Medium L.E').replace('_high', '_High L.E').replace('low', 'Low Education').replace('medium', 'Medium Education').replace('high', 'High Education')  # Update the category name
    ))

# Update the layout for better appearance
fig.update_geos(
    showcountries=True,
    countrycolor="black",
    showcoastlines=True,
    coastlinecolor="black",
    projection_type="natural earth"
)

fig.update_layout(
    title_text='Education vs Life Expectancy Bivariate Choropleth',
    margin={"r":0, "t":50, "l":0, "b":0},
    legend=dict(
        title="Categories",
        traceorder='normal'  # Ensure the legend follows the trace order
    ),
    geo=dict(
        lakecolor='#FFFFFF',
        bgcolor='#a8d5f2'  # Set the water color to #a8d5f2
    )
)

# Show the figure
fig.show()
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mFileNotFoundError[0m                         Traceback (most recent call last)
Cell [0;32mIn[1], line 6[0m
[1;32m      3[0m [38;5;28;01mimport[39;00m [38;5;21;01mplotly[39;00m[38;5;21;01m.[39;00m[38;5;21;01mgraph_objects[39;00m [38;5;28;01mas[39;00m [38;5;21;01mgo[39;00m
[1;32m      5[0m [38;5;66;03m# Load the CSV file[39;00m
[0;32m----> 6[0m data [38;5;241m=[39m [43mpd[49m[38;5;241;43m.[39;49m[43mread_csv[49m[43m([49m[38;5;124;43m'[39;49m[38;5;124;43mNormalized_Dataset_EDU.csv[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m      8[0m [38;5;66;03m# Convert the 'GDP' and 'Life expectancy' columns to numeric[39;00m
[1;32m      9[0m data[[38;5;124m'[39m[38;5;124mValue[39m[38;5;124m'[39m] [38;5;241m=[39m pd[38;5;241m.[39mto_numeric(data[[38;5;124m'[39m[38;5;124mValue[39m[38;5;124m'[39m], errors[38;5;241m=[39m[38;5;124m'[39m[38;5;124mcoerce[39m[38;5;124m'[39m)

File [0;32m~/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026[0m, in [0;36mread_csv[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)[0m
[1;32m   1013[0m kwds_defaults [38;5;241m=[39m _refine_defaults_read(
[1;32m   1014[0m     dialect,
[1;32m   1015[0m     delimiter,
[0;32m   (...)[0m
[1;32m   1022[0m     dtype_backend[38;5;241m=[39mdtype_backend,
[1;32m   1023[0m )
[1;32m   1024[0m kwds[38;5;241m.[39mupdate(kwds_defaults)
[0;32m-> 1026[0m [38;5;28;01mreturn[39;00m [43m_read[49m[43m([49m[43mfilepath_or_buffer[49m[43m,[49m[43m [49m[43mkwds[49m[43m)[49m

File [0;32m~/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620[0m, in [0;36m_read[0;34m(filepath_or_buffer, kwds)[0m
[1;32m    617[0m _validate_names(kwds[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mnames[39m[38;5;124m"[39m, [38;5;28;01mNone[39;00m))
[1;32m    619[0m [38;5;66;03m# Create the parser.[39;00m
[0;32m--> 620[0m parser [38;5;241m=[39m [43mTextFileReader[49m[43m([49m[43mfilepath_or_buffer[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwds[49m[43m)[49m
[1;32m    622[0m [38;5;28;01mif[39;00m chunksize [38;5;129;01mor[39;00m iterator:
[1;32m    623[0m     [38;5;28;01mreturn[39;00m parser

File [0;32m~/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620[0m, in [0;36mTextFileReader.__init__[0;34m(self, f, engine, **kwds)[0m
[1;32m   1617[0m     [38;5;28mself[39m[38;5;241m.[39moptions[[38;5;124m"[39m[38;5;124mhas_index_names[39m[38;5;124m"[39m] [38;5;241m=[39m kwds[[38;5;124m"[39m[38;5;124mhas_index_names[39m[38;5;124m"[39m]
[1;32m   1619[0m [38;5;28mself[39m[38;5;241m.[39mhandles: IOHandles [38;5;241m|[39m [38;5;28;01mNone[39;00m [38;5;241m=[39m [38;5;28;01mNone[39;00m
[0;32m-> 1620[0m [38;5;28mself[39m[38;5;241m.[39m_engine [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_make_engine[49m[43m([49m[43mf[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mengine[49m[43m)[49m

File [0;32m~/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880[0m, in [0;36mTextFileReader._make_engine[0;34m(self, f, engine)[0m
[1;32m   1878[0m     [38;5;28;01mif[39;00m [38;5;124m"[39m[38;5;124mb[39m[38;5;124m"[39m [38;5;129;01mnot[39;00m [38;5;129;01min[39;00m mode:
[1;32m   1879[0m         mode [38;5;241m+[39m[38;5;241m=[39m [38;5;124m"[39m[38;5;124mb[39m[38;5;124m"[39m
[0;32m-> 1880[0m [38;5;28mself[39m[38;5;241m.[39mhandles [38;5;241m=[39m [43mget_handle[49m[43m([49m
[1;32m   1881[0m [43m    [49m[43mf[49m[43m,[49m
[1;32m   1882[0m [43m    [49m[43mmode[49m[43m,[49m
[1;32m   1883[0m [43m    [49m[43mencoding[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43moptions[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mencoding[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m)[49m[43m,[49m
[1;32m   1884[0m [43m    [49m[43mcompression[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43moptions[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mcompression[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m)[49m[43m,[49m
[1;32m   1885[0m [43m    [49m[43mmemory_map[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43moptions[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mmemory_map[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;28;43;01mFalse[39;49;00m[43m)[49m[43m,[49m
[1;32m   1886[0m [43m    [49m[43mis_text[49m[38;5;241;43m=[39;49m[43mis_text[49m[43m,[49m
[1;32m   1887[0m [43m    [49m[43merrors[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43moptions[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mencoding_errors[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;124;43m"[39;49m[38;5;124;43mstrict[39;49m[38;5;124;43m"[39;49m[43m)[49m[43m,[49m
[1;32m   1888[0m [43m    [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43moptions[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mstorage_options[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m)[49m[43m,[49m
[1;32m   1889[0m [43m[49m[43m)[49m
[1;32m   1890[0m [38;5;28;01massert[39;00m [38;5;28mself[39m[38;5;241m.[39mhandles [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m
[1;32m   1891[0m f [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mhandles[38;5;241m.[39mhandle

File [0;32m~/miniconda3/envs/jupyterbook/lib/python3.10/site-packages/pandas/io/common.py:873[0m, in [0;36mget_handle[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)[0m
[1;32m    868[0m [38;5;28;01melif[39;00m [38;5;28misinstance[39m(handle, [38;5;28mstr[39m):
[1;32m    869[0m     [38;5;66;03m# Check whether the filename is to be opened in binary mode.[39;00m
[1;32m    870[0m     [38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.[39;00m
[1;32m    871[0m     [38;5;28;01mif[39;00m ioargs[38;5;241m.[39mencoding [38;5;129;01mand[39;00m [38;5;124m"[39m[38;5;124mb[39m[38;5;124m"[39m [38;5;129;01mnot[39;00m [38;5;129;01min[39;00m ioargs[38;5;241m.[39mmode:
[1;32m    872[0m         [38;5;66;03m# Encoding[39;00m
[0;32m--> 873[0m         handle [38;5;241m=[39m [38;5;28;43mopen[39;49m[43m([49m
[1;32m    874[0m [43m            [49m[43mhandle[49m[43m,[49m
[1;32m    875[0m [43m            [49m[43mioargs[49m[38;5;241;43m.[39;49m[43mmode[49m[43m,[49m
[1;32m    876[0m [43m            [49m[43mencoding[49m[38;5;241;43m=[39;49m[43mioargs[49m[38;5;241;43m.[39;49m[43mencoding[49m[43m,[49m
[1;32m    877[0m [43m            [49m[43merrors[49m[38;5;241;43m=[39;49m[43merrors[49m[43m,[49m
[1;32m    878[0m [43m            [49m[43mnewline[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43m"[39;49m[43m,[49m
[1;32m    879[0m [43m        [49m[43m)[49m
[1;32m    880[0m     [38;5;28;01melse[39;00m:
[1;32m    881[0m         [38;5;66;03m# Binary mode[39;00m
[1;32m    882[0m         handle [38;5;241m=[39m [38;5;28mopen[39m(handle, ioargs[38;5;241m.[39mmode)

[0;31mFileNotFoundError[0m: [Errno 2] No such file or directory: 'Normalized_Dataset_EDU.csv'

